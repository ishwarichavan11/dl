{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e081897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens : 0\n",
      "Number of types : 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5628\\1778928620.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Number of tokens : '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Number of types : '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TTR : '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_types\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import TweetTokenizer as tt\n",
    "import math\n",
    "tokens=[]\n",
    "d=dict()\n",
    "with open(r'train.csv','r',encoding=\"utf8\") as csvfile:\n",
    "    reader1=csv.reader(csvfile)\n",
    "    c=0\n",
    "    for i in reader1:\n",
    "        token=tt().tokenize(i[0])\n",
    "        actual=[]\n",
    "        for i in token:\n",
    "            k=re.findall(r\"[A-Za-z']+\",i)\n",
    "            if len(k)==1 and len(i)==len(k[0]):\n",
    "                if 'http' in k[0]:\n",
    "                    k=[k[0].replace('http','')]\n",
    "                if 'https' in k[0]:\n",
    "                    k=[k[0].replace('https','')]                    \n",
    "                k=[k[0].lower()]\n",
    "                if not ((len(k[0])==1 and (k[0]==\"'\" )) or len(k[0])==0):\n",
    "                    actual+=k\n",
    "                if k[0] in d:\n",
    "                    d[k[0]]+=1\n",
    "                else:\n",
    "                    d[k[0]]=1\n",
    "        tokens+=actual\n",
    "types=set(tokens)\n",
    "n_tokens=len(tokens)\n",
    "n_types=len(types)\n",
    "print('Number of tokens : '+str(n_tokens))\n",
    "print('Number of types : '+str(n_types))\n",
    "print('TTR : '+str(n_types/n_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zips law of length\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "frequency_types=dict()\n",
    "for i in tokens:\n",
    "    if i in frequency_types:\n",
    "        frequency_types[i]+=1\n",
    "    else:\n",
    "        frequency_types[i]=1\n",
    "#wordlength_frequency=dict()\n",
    "words_chosen=['show','complete','welcome','famous','holiday','champions','one','girls','parliament']\n",
    "\n",
    "axes=[]\n",
    "for i in words_chosen:\n",
    "    axes.append([len(i),frequency_types[i],i])\n",
    "axes.sort()\n",
    "x=[]\n",
    "y=[]\n",
    "for i in axes:\n",
    "    x.append(i[0])\n",
    "    y.append(i[1])\n",
    "\n",
    "plt.plot(x,y,color='maroon')\n",
    "plt.title(\"Zipf's law of length\")\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c64cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zips law of meaning\n",
    "l1=[]\n",
    "freq=[]\n",
    "num_meanings=[]\n",
    "words=['clubs','crackers','tip','matches','cases','starts','cover','deal','marks','getting','made']\n",
    "meanings=[]\n",
    "tokennumber=0\n",
    "for i in words:\n",
    "    c=0\n",
    "    mean_i=[]\n",
    "    for syn in wordnet.synsets(i):\n",
    "        for j in syn.lemmas():\n",
    "            mean_i.append(j.name())\n",
    "    meanings.append(mean_i)\n",
    "    num_meanings.append(len(set(mean_i)))\n",
    "    freq.append(frequency_types[i])\n",
    "\n",
    "plt.plot(freq,num_meanings,color='orange')\n",
    "plt.title(\"Zipf's Law of Meanings\")\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Number of Meanings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449abf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heaps law\n",
    "hash_map={}\n",
    "x=[]\n",
    "y=[0]\n",
    "for i in range(len(tokens)):\n",
    "    x.append(i+1)\n",
    "    if tokens[i] not in hash_map:\n",
    "        y.append(y[-1]+1)\n",
    "        hash_map[tokens[i]]=1\n",
    "    else:\n",
    "        y.append(y[-1])\n",
    "plt.plot(x,y[1:],color='purple')\n",
    "plt.title(\"Heap's law\")\n",
    "plt.xlabel('Size of corpus')\n",
    "plt.ylabel('Vocabulary size')\n",
    "plt.show()\n",
    "base=[10 for i in range(len(x))]\n",
    "a=np.log(x)/np.log(base)\n",
    "b=np.log(y[1:])/np.log(base)\n",
    "linfit=np.polyfit(a,b,1)\n",
    "print('k = '+str(10**linfit[1])+' and '+'ùõΩ = '+str(linfit[0]))\n",
    "plt.plot(x,y[1:],color='green')\n",
    "plt.xscale('log',basex=10)\n",
    "plt.yscale('log',basey=10)\n",
    "plt.title(\"Heap's law (log plot)\")\n",
    "plt.xlabel('Size of corpus')\n",
    "plt.ylabel('Vocabulary size')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db674dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fbe416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef8ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc8a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba65d967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33544ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46912dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41fcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
